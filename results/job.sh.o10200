Single Sentence Casei CNN 2
200, 20, relu
keep everything but operations static
loading data...
/home/s1045064/dissertation/repo-diss/sentence-classification/data/snli-w2v-Split.p
data loaded!
model architecture: CNN-non-static
using: word2vec vectors
[('image shape', 89, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 3]), ('dropout', [0.2]), ('batch_size', 200), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 9), ('shuffle_batch', True), ('mode', 'mul'), ('alpha', 0.4), ('beta', 0.6), ('activations', [<function Iden at 0x2e769b90>])]
define model architecture
define parameters of the model and update functions using adadelta
shuffle dataset and assign to mini batches. if dataset size is not a multiple of mini batches, replicate
divide train set into train/val sets
compile theano functions to get train/val/test errors
... training
epoch: 1, training time: 505.20 secs, train perf: 33.44 %, val perf: 34.36 %
epoch: 2, training time: 507.91 secs, train perf: 63.21 %, val perf: 63.00 %
epoch: 3, training time: 508.00 secs, train perf: 68.63 %, val perf: 67.80 %
epoch: 4, training time: 507.87 secs, train perf: 73.06 %, val perf: 71.04 %
epoch: 5, training time: 507.96 secs, train perf: 76.46 %, val perf: 73.57 %
epoch: 6, training time: 508.03 secs, train perf: 78.44 %, val perf: 75.04 %
epoch: 7, training time: 507.84 secs, train perf: 80.28 %, val perf: 76.31 %
epoch: 8, training time: 507.57 secs, train perf: 82.08 %, val perf: 77.41 %
epoch: 9, training time: 508.09 secs, train perf: 82.98 %, val perf: 77.18 %
epoch: 10, training time: 507.59 secs, train perf: 84.34 %, val perf: 77.55 %
epoch: 11, training time: 507.90 secs, train perf: 85.96 %, val perf: 77.98 %
epoch: 12, training time: 508.05 secs, train perf: 86.94 %, val perf: 77.60 %
epoch: 13, training time: 508.44 secs, train perf: 88.11 %, val perf: 77.71 %
epoch: 14, training time: 508.66 secs, train perf: 88.79 %, val perf: 77.33 %
epoch: 15, training time: 508.65 secs, train perf: 88.80 %, val perf: 76.40 %
epoch: 16, training time: 508.73 secs, train perf: 90.23 %, val perf: 77.31 %
epoch: 17, training time: 508.48 secs, train perf: 90.69 %, val perf: 77.27 %
epoch: 18, training time: 507.91 secs, train perf: 90.74 %, val perf: 76.73 %
epoch: 19, training time: 507.59 secs, train perf: 91.72 %, val perf: 76.87 %
epoch: 20, training time: 508.01 secs, train perf: 92.28 %, val perf: 76.38 %
epoch: 21, training time: 508.28 secs, train perf: 92.61 %, val perf: 76.67 %
epoch: 22, training time: 508.56 secs, train perf: 92.90 %, val perf: 76.65 %
epoch: 23, training time: 507.88 secs, train perf: 92.97 %, val perf: 76.14 %
epoch: 24, training time: 507.66 secs, train perf: 93.88 %, val perf: 76.31 %
epoch: 25, training time: 507.41 secs, train perf: 94.07 %, val perf: 76.53 %
0.7739
