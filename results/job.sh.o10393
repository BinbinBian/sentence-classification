Single Sentence Casei CNN 2
200, 15, relu
keep everything but operations static
loading data...
/home/s1045064/dissertation/repo-diss/sentence-classification/data/snli-w2v-Split.p
data loaded!
model architecture: CNN-non-static
using: word2vec vectors
[('image shape', 89, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 3]), ('dropout', [0.15]), ('batch_size', 200), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 9), ('shuffle_batch', True), ('mode', 'mix1'), ('alpha', 1.0), ('beta', 1.0), ('activations', [<function Iden at 0x2e373a28>])]
define model architecture
define parameters of the model and update functions using adadelta
shuffle dataset and assign to mini batches. if dataset size is not a multiple of mini batches, replicate
divide train set into train/val sets
compile theano functions to get train/val/test errors
... training
epoch: 1, training time: 524.06 secs, train perf: 74.43 %, val perf: 72.54 %
epoch: 2, training time: 528.61 secs, train perf: 81.65 %, val perf: 78.25 %
epoch: 3, training time: 527.66 secs, train perf: 84.42 %, val perf: 79.48 %
epoch: 4, training time: 526.78 secs, train perf: 87.03 %, val perf: 80.65 %
epoch: 5, training time: 527.04 secs, train perf: 88.60 %, val perf: 80.53 %
epoch: 6, training time: 527.43 secs, train perf: 88.85 %, val perf: 80.03 %
epoch: 7, training time: 526.80 secs, train perf: 90.84 %, val perf: 80.73 %
epoch: 8, training time: 524.41 secs, train perf: 92.32 %, val perf: 79.88 %
epoch: 9, training time: 523.79 secs, train perf: 91.86 %, val perf: 80.10 %
epoch: 10, training time: 523.87 secs, train perf: 93.46 %, val perf: 80.13 %
epoch: 11, training time: 523.87 secs, train perf: 94.09 %, val perf: 80.00 %
epoch: 12, training time: 524.78 secs, train perf: 94.98 %, val perf: 79.76 %
epoch: 13, training time: 529.14 secs, train perf: 95.24 %, val perf: 79.56 %
epoch: 14, training time: 530.01 secs, train perf: 95.48 %, val perf: 79.78 %
epoch: 15, training time: 529.52 secs, train perf: 96.07 %, val perf: 79.58 %
epoch: 16, training time: 528.47 secs, train perf: 96.23 %, val perf: 79.89 %
epoch: 17, training time: 528.74 secs, train perf: 96.49 %, val perf: 79.65 %
epoch: 18, training time: 524.63 secs, train perf: 96.79 %, val perf: 79.31 %
epoch: 19, training time: 523.97 secs, train perf: 96.97 %, val perf: 79.46 %
epoch: 20, training time: 523.96 secs, train perf: 96.94 %, val perf: 78.63 %
epoch: 21, training time: 523.90 secs, train perf: 97.23 %, val perf: 78.63 %
epoch: 22, training time: 524.42 secs, train perf: 97.56 %, val perf: 79.31 %
epoch: 23, training time: 525.09 secs, train perf: 97.71 %, val perf: 79.29 %
epoch: 24, training time: 529.57 secs, train perf: 97.96 %, val perf: 79.45 %
epoch: 25, training time: 529.93 secs, train perf: 98.02 %, val perf: 79.41 %
0.8005
