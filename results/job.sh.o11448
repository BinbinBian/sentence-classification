Single Sentence Casei CNN 2
200, 20, relu
loading data...
/home/s1045064/dissertation/repo-diss/sentence-classification/data/snli-w2v-Split.p
data loaded!
model architecture: CNN-non-static
using: word2vec vectors
[('image shape', 89, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 3]), ('dropout', [0.2]), ('batch_size', 200), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 9), ('shuffle_batch', True), ('mode', 'sub'), ('alpha', 1.0), ('beta', 1.0), ('activations', [<function ReLU at 0x2e17ede8>])]
define model architecture
define parameters of the model and update functions using adadelta
shuffle dataset and assign to mini batches. if dataset size is not a multiple of mini batches, replicate
divide train set into train/val sets
compile theano functions to get train/val/test errors
... training
epoch: 1, training time: 506.69 secs, train perf: 75.77 %, val perf: 73.86 %
epoch: 2, training time: 510.04 secs, train perf: 81.31 %, val perf: 78.17 %
epoch: 3, training time: 512.92 secs, train perf: 84.10 %, val perf: 79.50 %
epoch: 4, training time: 512.96 secs, train perf: 85.86 %, val perf: 79.75 %
epoch: 5, training time: 512.98 secs, train perf: 88.35 %, val perf: 80.09 %
epoch: 6, training time: 512.65 secs, train perf: 89.77 %, val perf: 80.53 %
epoch: 7, training time: 512.33 secs, train perf: 91.04 %, val perf: 80.39 %
epoch: 8, training time: 511.74 secs, train perf: 92.15 %, val perf: 79.89 %
epoch: 9, training time: 511.84 secs, train perf: 92.61 %, val perf: 79.81 %
epoch: 10, training time: 511.73 secs, train perf: 93.23 %, val perf: 79.81 %
epoch: 11, training time: 511.75 secs, train perf: 94.20 %, val perf: 79.77 %
epoch: 12, training time: 511.94 secs, train perf: 94.84 %, val perf: 79.54 %
epoch: 13, training time: 511.36 secs, train perf: 95.39 %, val perf: 79.47 %
epoch: 14, training time: 507.46 secs, train perf: 95.45 %, val perf: 79.43 %
epoch: 15, training time: 511.95 secs, train perf: 96.13 %, val perf: 79.08 %
epoch: 16, training time: 512.21 secs, train perf: 96.24 %, val perf: 78.96 %
epoch: 17, training time: 512.29 secs, train perf: 96.61 %, val perf: 79.24 %
epoch: 18, training time: 512.61 secs, train perf: 96.70 %, val perf: 79.15 %
epoch: 19, training time: 512.74 secs, train perf: 96.96 %, val perf: 78.98 %
epoch: 20, training time: 512.75 secs, train perf: 97.20 %, val perf: 79.24 %
epoch: 21, training time: 513.03 secs, train perf: 97.43 %, val perf: 79.47 %
epoch: 22, training time: 512.63 secs, train perf: 97.40 %, val perf: 79.30 %
epoch: 23, training time: 515.05 secs, train perf: 97.78 %, val perf: 78.95 %
epoch: 24, training time: 512.82 secs, train perf: 97.95 %, val perf: 79.39 %
epoch: 25, training time: 512.92 secs, train perf: 97.87 %, val perf: 78.86 %
0.7932
