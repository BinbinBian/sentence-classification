200, 0.0, relu
loading data...
data loaded!
model architecture: CNN-static
using: word2vec vectors
----------------------
        CNN 0       
----------------------
datasets configured.
relu
False 200 0.0
[('image shape', 89, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 3]), ('dropout', [0.0]), ('batch_size', 200), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 9), ('shuffle_batch', True)]
define model architecture
define parameters of the model and update functions using adadelta
shuffle dataset and assign to mini batches. if dataset size is not a multiple of mini batches, replicate
divide train set into train/val sets
compile theano functions to get train/val/test errors
na maika ti v putkata
... training
epoch: 1, training time: 225.40 secs, train perf: 33.27 %, val perf: 32.88 %
epoch: 2, training time: 227.59 secs, train perf: 33.43 %, val perf: 34.19 %
epoch: 3, training time: 227.63 secs, train perf: 33.42 %, val perf: 34.27 %
epoch: 4, training time: 227.59 secs, train perf: 33.34 %, val perf: 33.05 %
epoch: 5, training time: 227.70 secs, train perf: 33.44 %, val perf: 34.36 %
epoch: 6, training time: 227.90 secs, train perf: 33.25 %, val perf: 32.74 %
epoch: 7, training time: 228.01 secs, train perf: 33.44 %, val perf: 34.36 %
epoch: 8, training time: 228.00 secs, train perf: 33.44 %, val perf: 34.36 %
epoch: 9, training time: 227.99 secs, train perf: 33.34 %, val perf: 33.29 %
epoch: 10, training time: 228.35 secs, train perf: 33.22 %, val perf: 32.35 %
epoch: 11, training time: 228.90 secs, train perf: 33.22 %, val perf: 32.40 %
epoch: 12, training time: 229.98 secs, train perf: 33.44 %, val perf: 34.36 %
epoch: 13, training time: 229.80 secs, train perf: 33.22 %, val perf: 32.35 %
epoch: 14, training time: 228.54 secs, train perf: 33.44 %, val perf: 34.36 %
epoch: 15, training time: 228.69 secs, train perf: 33.23 %, val perf: 32.37 %
epoch: 16, training time: 228.53 secs, train perf: 33.22 %, val perf: 32.35 %
epoch: 17, training time: 229.93 secs, train perf: 33.22 %, val perf: 32.35 %
epoch: 18, training time: 229.66 secs, train perf: 33.44 %, val perf: 34.36 %
epoch: 19, training time: 228.77 secs, train perf: 33.34 %, val perf: 33.29 %
epoch: 20, training time: 230.06 secs, train perf: 33.44 %, val perf: 34.36 %
epoch: 21, training time: 229.84 secs, train perf: 33.22 %, val perf: 32.35 %
epoch: 22, training time: 229.15 secs, train perf: 33.22 %, val perf: 32.35 %
epoch: 23, training time: 230.33 secs, train perf: 33.34 %, val perf: 33.29 %
epoch: 24, training time: 229.94 secs, train perf: 33.34 %, val perf: 33.29 %
epoch: 25, training time: 229.24 secs, train perf: 33.44 %, val perf: 34.36 %
subrah kvot mi trqbvashe
perf: 0.3413
0.3413
using: word2vec vectors
----------------------
        CNN 1       
----------------------
datasets configured.
vikam sledvashtata funkcia
[('image shape', 89, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 3]), ('dropout', [0.0]), ('batch_size', 200), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 9), ('shuffle_batch', True)]
define model architecture
define parameters of the model and update functions using adadelta
shuffle dataset and assign to mini batches. if dataset size is not a multiple of mini batches, replicate
divide train set into train/val sets
compile theano functions to get train/val/test errors
na maika ti v putkata
... training
epoch: 1, training time: 228.96 secs, train perf: 66.29 %, val perf: 65.42 %
epoch: 2, training time: 231.50 secs, train perf: 68.06 %, val perf: 65.77 %
epoch: 3, training time: 231.39 secs, train perf: 67.94 %, val perf: 64.96 %
epoch: 4, training time: 230.59 secs, train perf: 70.71 %, val perf: 66.14 %
epoch: 5, training time: 231.60 secs, train perf: 71.02 %, val perf: 65.50 %
epoch: 6, training time: 230.27 secs, train perf: 72.85 %, val perf: 66.09 %
epoch: 7, training time: 230.42 secs, train perf: 74.01 %, val perf: 66.19 %
epoch: 8, training time: 230.14 secs, train perf: 74.52 %, val perf: 66.04 %
epoch: 9, training time: 232.35 secs, train perf: 75.88 %, val perf: 66.10 %
epoch: 10, training time: 229.59 secs, train perf: 76.66 %, val perf: 66.51 %
epoch: 11, training time: 236.48 secs, train perf: 77.33 %, val perf: 65.68 %
epoch: 12, training time: 238.27 secs, train perf: 78.35 %, val perf: 65.64 %
epoch: 13, training time: 239.02 secs, train perf: 79.01 %, val perf: 66.08 %
epoch: 14, training time: 236.60 secs, train perf: 79.15 %, val perf: 65.53 %
epoch: 15, training time: 232.32 secs, train perf: 80.32 %, val perf: 65.90 %
epoch: 16, training time: 229.44 secs, train perf: 80.84 %, val perf: 65.31 %
epoch: 17, training time: 229.02 secs, train perf: 81.30 %, val perf: 66.08 %
epoch: 18, training time: 565.32 secs, train perf: 81.93 %, val perf: 65.33 %
epoch: 19, training time: 699.50 secs, train perf: 82.47 %, val perf: 65.66 %
epoch: 20, training time: 232.98 secs, train perf: 82.53 %, val perf: 65.32 %
epoch: 21, training time: 229.77 secs, train perf: 83.13 %, val perf: 65.41 %
epoch: 22, training time: 229.35 secs, train perf: 82.53 %, val perf: 65.05 %
epoch: 23, training time: 228.38 secs, train perf: 84.21 %, val perf: 65.95 %
epoch: 24, training time: 228.30 secs, train perf: 84.62 %, val perf: 64.95 %
epoch: 25, training time: 228.44 secs, train perf: 84.96 %, val perf: 65.85 %
perf: 0.6583
0.6583
concatenating the two sentences
first sentences concatenated.
Saving into text files
